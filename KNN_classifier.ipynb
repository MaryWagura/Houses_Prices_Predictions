{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51bb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03364d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset...\n",
      "Training set: (50000, 784)\n",
      "Test set: (20000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# Split into 50,000 train and 20,000 test\n",
    "X_train, X_test = X[:50000], X[50000:]\n",
    "y_train, y_test = y[:50000], y[50000:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54011439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaled to 0-1 range\n",
      "Pixel value range: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Scale pixel values from 0-255 to 0-1 (KNN is distance-based!)\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0\n",
    "\n",
    "print(\"Data scaled to 0-1 range\")\n",
    "print(f\"Pixel value range: [{X_train_scaled.min():.1f}, {X_train_scaled.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a66113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline KNN Classifier...\n",
      "Baseline KNN Accuracy: 0.9691\n",
      "Training time: 0.45 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Baseline KNN Classifier...\")\n",
    "\n",
    "# Start with default parameters\n",
    "knn_baseline = KNeighborsClassifier()\n",
    "start_time = time.time()\n",
    "\n",
    "knn_baseline.fit(X_train_scaled, y_train)\n",
    "baseline_time = time.time() - start_time\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_score = knn_baseline.score(X_test_scaled, y_test)\n",
    "print(f\"Baseline KNN Accuracy: {baseline_score:.4f}\")\n",
    "print(f\"Training time: {baseline_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49dd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for KNN\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_neighbors': [3, 4, 5],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Set up grid search with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    knn, \n",
    "    param_grid, \n",
    "    cv=3, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37261cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search (this may take a while)...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting grid search (this may take a while)...\")\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f\"Grid search completed in {grid_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search Results:\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Show all results\n",
    "print(\"\\nAll parameter combinations:\")\n",
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(f\"  {mean_score:.4f} for {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e478dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best estimator from grid search\n",
    "best_knn = grid_search.best_estimator_\n",
    "print(f\"Final model parameters: {best_knn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4481e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Check if we achieved the goal\n",
    "if test_accuracy >= 0.97:\n",
    "    print(\"🎉 SUCCESS: Achieved target accuracy of 97% or higher!\")\n",
    "else:\n",
    "    print(\"⚠️  Target not reached. Consider expanding hyperparameter search.\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2808e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define classifiers to compare\n",
    "classifiers = {\n",
    "    'KNN (Tuned)': best_knn,\n",
    "    'SGD': SGDClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM Linear': SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Training and comparing classifiers...\")\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if name != 'KNN (Tuned)':  # We already trained KNN\n",
    "        # Scale data for SVM (KNN already scaled)\n",
    "        if name == 'SVM Linear':\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            accuracy = clf.score(X_test_scaled, y_test)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            accuracy = clf.score(X_test, y_test)\n",
    "    else:\n",
    "        accuracy = test_accuracy  # Use our already computed accuracy\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    results[name] = {'accuracy': accuracy, 'time': train_time}\n",
    "    \n",
    "    print(f\"{name:15} | Accuracy: {accuracy:.4f} | Time: {train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in names]\n",
    "colors = ['green' if acc >= 0.97 else 'blue' for acc in accuracies]\n",
    "\n",
    "bars = plt.bar(names, accuracies, color=colors, alpha=0.7)\n",
    "plt.axhline(y=0.97, color='red', linestyle='--', label='Target (97%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classifier Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, accuracy in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{accuracy:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Training time comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "times = [results[name]['time'] for name in names]\n",
    "plt.bar(names, times, color='orange', alpha=0.7)\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - KNN Classifier')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, range(10))\n",
    "plt.yticks(tick_marks, range(10))\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified examples\n",
    "misclassified_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    print(f\"Number of misclassified examples: {len(misclassified_indices)}\")\n",
    "    \n",
    "    # Show first few misclassified examples\n",
    "    print(\"\\nFirst 5 misclassified examples:\")\n",
    "    for i in range(min(5, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        print(f\"True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n",
    "        \n",
    "        # Optional: Display the image\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(X_test[idx].reshape(28, 28), cmap='binary')\n",
    "        plt.title(f'True: {y_test[idx]}, Pred: {y_pred[idx]}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No misclassifications found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUMMARY AND KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"🎯 Target Accuracy: 97%\")\n",
    "print(f\"✅ KNN Achieved Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "if test_accuracy >= 0.97:\n",
    "    print(\"🎉 GOAL ACHIEVED: KNN classifier exceeded 97% accuracy!\")\n",
    "else:\n",
    "    print(\"⚠️  GOAL NOT REACHED: Consider trying:\")\n",
    "    print(\"   - Larger hyperparameter grid (n_neighbors: [1, 3, 5, 7, 9])\")\n",
    "    print(\"   - Data augmentation\")\n",
    "    print(\"   - Feature engineering\")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Most accurate competing classifier: {max([(name, res['accuracy']) for name, res in results.items() if name != 'KNN (Tuned)'], key=lambda x: x[1])}\")\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nPerformance Ranking:\")\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
    "for i, (name, res) in enumerate(sorted_results, 1):\n",
    "    print(f\"{i}. {name:15}: {res['accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
